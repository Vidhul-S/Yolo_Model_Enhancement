{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mGmQbAO5pQb"
   },
   "source": [
    "# 1.Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE\n"
     ]
    }
   ],
   "source": [
    "#%pip install ultralytics\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "print(os.getenv(\"KMP_DUPLICATE_LIB_OK\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wbvMlHd_QwMG",
    "outputId": "2e992f9f-90bb-4668-de12-fed629975285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.49  Python-3.8.20 torch-2.4.1 CUDA:0 (NVIDIA GeForce RTX 4090, 24564MiB)\n",
      "Setup complete  (32 CPUs, 127.7 GB RAM, 929.1/950.9 GB disk)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ultralytics\n",
    "from ultralytics import YOLO\n",
    "ultralytics.checks()\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from scipy.optimize import minimize\n",
    "import json\n",
    "import joblib\n",
    "from sklearn.svm import SVR  # Support Vector Regression\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"******************\")\n",
    "project = rf.workspace(\"********\").project(\"udw\") # Check the data.yaml file to get the download link\n",
    "version = project.version(8)\n",
    "dataset = version.download(\"yolov11\")\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZY2VXXXu74w5"
   },
   "source": [
    "# 2. Train YOLOv11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1NcFxRcFdJ_O",
    "outputId": "952f35f7-666f-4121-fbdf-2b3a33b28081"
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO('yolo11n.yaml')  # build a new model from scratch\n",
    "model = YOLO('yolo11n.pt')  # load a pretrained model (recommended for training)\n",
    "\n",
    "# Use the model\n",
    "results = model.train(data=\"../UDW-8/data.yaml\", epochs=500, workers=0 )  # train the model \n",
    "results = model.val()  # evaluate model performance on the validation set\n",
    "#results = model('https://ultralytics.com/images/bus.jpg')  # predict on an image\n",
    "#results = model.export(format='onnx')  # export the model to ONNX format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. RESUME TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the partially trained model\n",
    "model = YOLO(\"..runs\\\\detect\\\\train6\\\\weights\\\\last.pt\")\n",
    "\n",
    "# Resume training\n",
    "results = model.train(resume=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. SVM MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configurations from YAML files\n",
    "with open('..UDW-8\\\\data.yaml', 'r') as f:\n",
    "    data_config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset paths\n",
    "train_path = Path(data_config['train'])\n",
    "val_path = Path(data_config['val'])\n",
    "test_path = Path(data_config['test'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM model\n",
    "svm_model = SVR(kernel=\"rbf\", C=1.0, epsilon=0.1)  # Initialize SVM regressor\n",
    "#Load Yolo model\n",
    "model = YOLO(\"Yolov11 custom model/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ground_truth_from_labels(label_path):\n",
    "    \"\"\"\n",
    "    Loads ground truth bounding boxes for a given image from the labels directory.\n",
    "    Assumes YOLO format annotations are stored in .txt files with the same name as the image.\n",
    "    \"\"\"\n",
    "    ground_truth_boxes = []\n",
    "    with open(label_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) < 5:\n",
    "                continue  # Skip invalid lines\n",
    "            _, x_center, y_center, width, height = map(float, parts)\n",
    "            ground_truth_boxes.append([x_center, y_center, width, height])\n",
    "\n",
    "    return ground_truth_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_to_xyxy(box, img_width, img_height):\n",
    "    \"\"\"\n",
    "    Convert YOLO format bounding box to xyxy format.\n",
    "    Args:\n",
    "    - box: [x_center, y_center, width, height] in YOLO normalized format.\n",
    "    - img_width, img_height: Dimensions of the image.\n",
    "    \n",
    "    Returns:\n",
    "    - xyxy: [x_min, y_min, x_max, y_max].\n",
    "    \"\"\"\n",
    "    x_center, y_center, width, height = box\n",
    "    x_min = (x_center - width / 2) * img_width\n",
    "    y_min = (y_center - height / 2) * img_height\n",
    "    x_max = (x_center + width / 2) * img_width\n",
    "    y_max = (y_center + height / 2) * img_height\n",
    "    return [x_min, y_min, x_max, y_max]\n",
    "\n",
    "def compute_iou(box1, box2):\n",
    "    \"\"\"\n",
    "    Compute IoU between two bounding boxes in xyxy format.\n",
    "    Args:\n",
    "    - box1, box2: [x_min, y_min, x_max, y_max].\n",
    "\n",
    "    Returns:\n",
    "    - IoU value as a float.\n",
    "    \"\"\"\n",
    "    x_min = max(box1[0], box2[0])\n",
    "    y_min = max(box1[1], box2[1])\n",
    "    x_max = min(box1[2], box2[2])\n",
    "    y_max = min(box1[3], box2[3])\n",
    "\n",
    "    intersection = max(0, x_max - x_min) * max(0, y_max - y_min)\n",
    "    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "\n",
    "    union = area1 + area2 - intersection\n",
    "    return intersection / union if union > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou_for_image(image_path ,yolo_model):\n",
    "    \"\"\"\n",
    "    Calculate IoU for each detected object against the ground truth.\n",
    "    Args:\n",
    "    - image_path: Path to the image.\n",
    "    - yaml_file: Path to the dataset YAML file.\n",
    "    - yolo_model: YOLO model object.\n",
    "\n",
    "    Returns:\n",
    "    - iou_scores: List of IoU scores for each prediction.\n",
    "    \"\"\"\n",
    "    # Load ground truth bounding boxes\n",
    "    # Extract the file name without extension\n",
    "    dir_path, file_name = os.path.split(image_path)\n",
    "    file_name_without_ext, ext = os.path.splitext(file_name)\n",
    "\n",
    "    # Replace 'images' with 'label' and append the '.txt' extension\n",
    "    label_path = os.path.join(dir_path.replace(\"images\", \"labels\"), file_name_without_ext + \".txt\")\n",
    "    \n",
    "    if not os.path.exists(label_path):\n",
    "        raise ValueError(f\"Annotation file {label_path} not found.\")\n",
    "    \n",
    "    ground_truth_boxes = load_ground_truth_from_labels(label_path)\n",
    "\n",
    "    # Load image and run detection\n",
    "    results = yolo_model.predict(image_path)\n",
    "    predictions = results[0].boxes  # Predicted boxes\n",
    "\n",
    "    # Load image dimensions\n",
    "    image = results[0].orig_img\n",
    "    img_height, img_width = image.shape[:2]\n",
    "\n",
    "    # Convert ground truth boxes to xyxy format\n",
    "    ground_truth_xyxy = [yolo_to_xyxy(box, img_width, img_height) for box in ground_truth_boxes]\n",
    "\n",
    "    # Extract predictions in xyxy format\n",
    "    predicted_boxes = predictions.xyxy.cpu().numpy()\n",
    "\n",
    "    # Compute IoU scores\n",
    "    iou_scores = []\n",
    "    for pred_box in predicted_boxes:\n",
    "        iou_with_all_gt = [compute_iou(pred_box[:4], gt_box) for gt_box in ground_truth_xyxy]\n",
    "        best_iou = max(iou_with_all_gt) if iou_with_all_gt else 0\n",
    "        iou_scores.append(best_iou)\n",
    "\n",
    "    return iou_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yolo_outputs(image,image_path):\n",
    "    \n",
    "    \"\"\"Runs YOLOv11 on an image and returns outputs.\"\"\"\n",
    "    results = model.predict(image)\n",
    "    # print(type(results))\n",
    "    # Extract confidence and IoU scores (adapt based on YOLOv11 output structure)\n",
    "    if hasattr(results[0].boxes, 'xyxy') and len(results[0].boxes.xyxy) > 0:\n",
    "        confidences = results[0].boxes.conf.cpu().numpy()  # Confidence scores results[0].boxes.id.int().cpu().tolist()\n",
    "        # print(confidences)\n",
    "        iou_score = np.array(calculate_iou_for_image(image_path , model) )   # IoU scores\n",
    "        return confidences.mean(), iou_score.mean()\n",
    "    else:\n",
    "        raise ValueError(\"Invalid YOLO output structure. Please verify model compatibility.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation parameters to predict\n",
    "PARAMETERS = ['brightness', 'gamma', 'contrast', 'hue', 'invert', 'solarize', 'posterize', 'gaussian_blur', 'saturation', 'sharpness']\n",
    "\n",
    "# Apply transformations based on parameters\n",
    "def apply_transformations(image, params):\n",
    "    transform_list = []\n",
    "    \n",
    "    transform_list.append(T.ColorJitter(brightness=params[0], contrast=params[2], saturation=params[8], hue=params[3]))\n",
    "    if params[4]:  # Invert\n",
    "        transform_list.append(T.RandomInvert())\n",
    "    transform_list.append(T.RandomSolarize(params[5]))\n",
    "    transform_list.append(T.RandomPosterize(bits=int(params[6])))\n",
    "    transform_list.append(T.GaussianBlur(kernel_size=(5, 5), sigma=params[7]))\n",
    "    transform_list.append(T.RandomAdjustSharpness(sharpness_factor=params[9]))\n",
    "\n",
    "    transform = T.Compose(transform_list)\n",
    "    return transform(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self-supervised optimization objective\n",
    "def optimization_objective(params, image,img_path):\n",
    "    transformed_image = apply_transformations(image, params)\n",
    "    conf, iou = get_yolo_outputs(transformed_image,img_path)\n",
    "    # Maximize confidence and IoU, minimize negative sum\n",
    "    return -(conf + iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize transformation parameters\n",
    "def optimize_parameters(image,img_path):\n",
    "    initial_params = np.random.rand(len(PARAMETERS))  # Random initialization\n",
    "    bounds = [(0, 1), (0.5, 2), (0, 1), (-0.5, 0.5), (0, 1), (0, 255), (1, 8), (0, 5), (0, 2), (0, 2)]\n",
    "\n",
    "    result = minimize(optimization_objective, initial_params, args=(image,img_path), bounds=bounds, method='L-BFGS-B')\n",
    "    return result.x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_processing(image_paths, epoch, batch_size):\n",
    "    features = []\n",
    "    targets = []  # Targets are YOLO confidences + IoU scores\n",
    "    for i in range(0, len(image_paths), batch_size):\n",
    "        batch = image_paths[i:i+batch_size]\n",
    "\n",
    "        for img_path in batch:\n",
    "            try:\n",
    "                # Debugging log\n",
    "                print(f\"Processing image: {img_path}\")\n",
    "\n",
    "                # Load image as float\n",
    "                image = cv2.imread(img_path, cv2.IMREAD_COLOR).astype('float32')\n",
    "                image = torch.from_numpy(image)\n",
    "                image = image.unsqueeze(0)  # Adds a batch dimension\n",
    "                image = image.permute(0, 3, 1, 2)\n",
    "                #image = T.ToTensor()(Image.open(img_path))\n",
    "                #image = image.type(torch.float32) / 128.0 - 1.0 # [-1, 1]\n",
    "                #image = (image + 1.0) * 128.0  # case [-1, 1]\n",
    "                image = image.type(torch.float32) / 255.0  # [0, 1]\n",
    "                #image = image * 255.0  # case [0, 1]\n",
    "                #image = torch.clip(image, 0.0, 255.0)\n",
    "                #image = image.type(torch.uint8)\n",
    "\n",
    "                \n",
    "                # Debugging log for YOLO outputs\n",
    "                conf, iou = get_yolo_outputs(image,img_path)\n",
    "                print(f\"YOLO Output - Confidence: {conf}, IoU: {iou}\")\n",
    "            \n",
    "                # Optimize parameters for each image\n",
    "                optimized_params = optimize_parameters(image,img_path)\n",
    "\n",
    "                # Debugging log for optimized parameters\n",
    "                print(f\"Optimized Parameters: {optimized_params}\")\n",
    "\n",
    "                # Apply optimized transformations\n",
    "                transformed_image = apply_transformations(image, optimized_params)\n",
    "\n",
    "                # Recheck YOLO outputs after transformations\n",
    "                new_conf, new_iou = get_yolo_outputs(transformed_image,img_path)\n",
    "                print(f\"Transformed YOLO Output - Confidence: {new_conf}, IoU: {new_iou}\")\n",
    "\n",
    "                # Collect features and targets for SVM training\n",
    "                features.append(optimized_params.tolist())\n",
    "                targets.append(new_conf + new_iou)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image {img_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "    # Safeguard: Check if features and targets are not empty\n",
    "    if not features or not targets:\n",
    "        raise ValueError(f\"No valid data generated in epoch {epoch}. Please check the input images and YOLO model.\")\n",
    "\n",
    "    print(f\"Epoch {epoch}: Processed {len(features)} images.\")\n",
    "    return np.array(features), np.array(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm_model(features, targets):\n",
    "    \"\"\"Train SVM using YOLO features (confidence, IoU) and transformation parameters as input.\"\"\"\n",
    "    # Reshape features to ensure 2D array format\n",
    "    if features.ndim == 1:\n",
    "        features = features.reshape(-1, 1)\n",
    "    if targets.ndim == 1:\n",
    "        targets = targets.reshape(-1)\n",
    "\n",
    "    svm_model.fit(features, targets)\n",
    "    print(\"SVM model trained successfully.\")\n",
    "    return svm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to JSON files\n",
    "def save_results(results, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "\n",
    "# Save SVM model\n",
    "def save_model(model, filename):\n",
    "    joblib.dump(model, filename)\n",
    "    print(f\"SVM model saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_pipeline(epochs, batch_size):\n",
    "    # Load training, validation, and test images from data.yaml paths\n",
    "    train_images = list(Path(data_config['train']).glob(\"*.jpg\"))\n",
    "    val_images = list(Path(data_config['val']).glob(\"*.jpg\"))\n",
    "    test_images = list(Path(data_config['test']).glob(\"*.jpg\"))\n",
    "    print(len(train_images))\n",
    "    # Training Loop with Epochs\n",
    "    for epoch in range(epochs):\n",
    "        train_features, train_targets = batch_processing(train_images, epoch,batch_size)\n",
    "        svm_model = train_svm_model(train_features, train_targets)\n",
    "\n",
    "    # Save the trained SVM model after training is complete\n",
    "    save_model(svm_model, 'trained_svm_model.joblib')\n",
    "\n",
    "    # Validation phase (only save results)\n",
    "    val_features, val_targets = batch_processing(val_images, epoch=\"Validation\")\n",
    "    save_results({\"features\": val_features.tolist(), \"targets\": val_targets.tolist()}, \"validation_results.json\")\n",
    "\n",
    "    # Testing phase (only save results)\n",
    "    test_features, test_targets = batch_processing(test_images, epoch=\"Testing\")\n",
    "    save_results({\"features\": test_features.tolist(), \"targets\": test_targets.tolist()}, \"testing_results.json\")\n",
    "\n",
    "    return {\n",
    "        \"train\": {\"features\": train_features, \"targets\": train_targets},\n",
    "        \"val\": {\"features\": val_features, \"targets\": val_targets},\n",
    "        \"test\": {\"features\": test_features, \"targets\": test_targets},\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = main_pipeline(10,12)\n",
    "print(\"Pipeline executed successfully. Results and model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod u+rwx /workspaces/Yolo_Model_Enhancement/train6.zip"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "YOLO11 Tutorial",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
